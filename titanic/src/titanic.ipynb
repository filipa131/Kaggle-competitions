{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2024-12-18 15:22:44,136] A new study created in memory with name: no-name-34416dc4-012a-422b-a7d5-f38c9bcaad71\n",
      "[I 2024-12-18 15:22:44,383] Trial 0 finished with value: 0.8071748878923767 and parameters: {'model': 'RandomForest', 'n_estimators': 256, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.8071748878923767.\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6996\\1016786673.py:79: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6996\\1016786673.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0)\n",
      "[I 2024-12-18 15:22:44,730] Trial 1 finished with value: 0.8161434977578476 and parameters: {'model': 'GradientBoosting', 'n_estimators': 172, 'learning_rate': 0.013994729535497262, 'max_depth': 6, 'subsample': 0.83127134038226}. Best is trial 1 with value: 0.8161434977578476.\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6996\\1016786673.py:79: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6996\\1016786673.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0)\n",
      "[I 2024-12-18 15:22:44,940] Trial 2 finished with value: 0.8071748878923767 and parameters: {'model': 'GradientBoosting', 'n_estimators': 129, 'learning_rate': 0.007234217444266342, 'max_depth': 5, 'subsample': 0.760646937718338}. Best is trial 1 with value: 0.8161434977578476.\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6996\\1016786673.py:79: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6996\\1016786673.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0)\n",
      "[I 2024-12-18 15:22:45,263] Trial 3 finished with value: 0.8430493273542601 and parameters: {'model': 'GradientBoosting', 'n_estimators': 161, 'learning_rate': 0.013583715227801349, 'max_depth': 6, 'subsample': 0.7945475301527058}. Best is trial 3 with value: 0.8430493273542601.\n",
      "[I 2024-12-18 15:22:45,614] Trial 4 finished with value: 0.8340807174887892 and parameters: {'model': 'RandomForest', 'n_estimators': 275, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8430493273542601.\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6996\\1016786673.py:79: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6996\\1016786673.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0)\n",
      "[I 2024-12-18 15:22:46,293] Trial 5 finished with value: 0.8251121076233184 and parameters: {'model': 'GradientBoosting', 'n_estimators': 209, 'learning_rate': 0.01023237967286471, 'max_depth': 7, 'subsample': 0.8058030686863706}. Best is trial 3 with value: 0.8430493273542601.\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6996\\1016786673.py:79: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6996\\1016786673.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0)\n",
      "[I 2024-12-18 15:22:46,601] Trial 6 finished with value: 0.8116591928251121 and parameters: {'model': 'GradientBoosting', 'n_estimators': 292, 'learning_rate': 0.0088524562490755, 'max_depth': 3, 'subsample': 0.8495787008672626}. Best is trial 3 with value: 0.8430493273542601.\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6996\\1016786673.py:79: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6996\\1016786673.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0)\n",
      "[I 2024-12-18 15:22:46,845] Trial 7 finished with value: 0.7802690582959642 and parameters: {'model': 'GradientBoosting', 'n_estimators': 243, 'learning_rate': 0.0019043664556391653, 'max_depth': 3, 'subsample': 0.9259575725532604}. Best is trial 3 with value: 0.8430493273542601.\n",
      "[I 2024-12-18 15:22:47,038] Trial 8 finished with value: 0.8295964125560538 and parameters: {'model': 'RandomForest', 'n_estimators': 193, 'max_depth': 18, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8430493273542601.\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6996\\1016786673.py:79: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6996\\1016786673.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0)\n",
      "[I 2024-12-18 15:22:47,296] Trial 9 finished with value: 0.8251121076233184 and parameters: {'model': 'GradientBoosting', 'n_estimators': 164, 'learning_rate': 0.021560367510108345, 'max_depth': 5, 'subsample': 0.8939488853414627}. Best is trial 3 with value: 0.8430493273542601.\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6996\\1016786673.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e5),\n",
      "[I 2024-12-18 15:22:47,338] Trial 10 finished with value: 0.8071748878923767 and parameters: {'model': 'LogisticRegression', 'C': 37226.11810448373, 'solver': 'lbfgs'}. Best is trial 3 with value: 0.8430493273542601.\n",
      "[I 2024-12-18 15:22:47,465] Trial 11 finished with value: 0.7892376681614349 and parameters: {'model': 'RandomForest', 'n_estimators': 114, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.8430493273542601.\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6996\\1016786673.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e5),\n",
      "[I 2024-12-18 15:22:47,472] Trial 12 finished with value: 0.600896860986547 and parameters: {'model': 'LogisticRegression', 'C': 1.3428543298739042e-05, 'solver': 'liblinear'}. Best is trial 3 with value: 0.8430493273542601.\n",
      "[I 2024-12-18 15:22:47,741] Trial 13 finished with value: 0.8116591928251121 and parameters: {'model': 'RandomForest', 'n_estimators': 299, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8430493273542601.\n",
      "[I 2024-12-18 15:22:47,968] Trial 14 finished with value: 0.8251121076233184 and parameters: {'model': 'RandomForest', 'n_estimators': 229, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.8430493273542601.\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6996\\1016786673.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e5),\n",
      "[I 2024-12-18 15:22:47,977] Trial 15 finished with value: 0.8071748878923767 and parameters: {'model': 'LogisticRegression', 'C': 0.3232974474911367, 'solver': 'lbfgs'}. Best is trial 3 with value: 0.8430493273542601.\n",
      "[I 2024-12-18 15:22:48,113] Trial 16 finished with value: 0.8295964125560538 and parameters: {'model': 'RandomForest', 'n_estimators': 140, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.8430493273542601.\n",
      "[I 2024-12-18 15:22:48,371] Trial 17 finished with value: 0.8295964125560538 and parameters: {'model': 'RandomForest', 'n_estimators': 266, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8430493273542601.\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6996\\1016786673.py:79: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6996\\1016786673.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0)\n",
      "[I 2024-12-18 15:22:48,563] Trial 18 finished with value: 0.820627802690583 and parameters: {'model': 'GradientBoosting', 'n_estimators': 164, 'learning_rate': 0.060903354318262846, 'max_depth': 4, 'subsample': 0.7014591958990174}. Best is trial 3 with value: 0.8430493273542601.\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6996\\1016786673.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e5),\n",
      "[I 2024-12-18 15:22:48,572] Trial 19 finished with value: 0.8071748878923767 and parameters: {'model': 'LogisticRegression', 'C': 25079.208296340246, 'solver': 'liblinear'}. Best is trial 3 with value: 0.8430493273542601.\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6996\\1016786673.py:79: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6996\\1016786673.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0)\n",
      "[I 2024-12-18 15:22:48,886] Trial 20 finished with value: 0.7802690582959642 and parameters: {'model': 'GradientBoosting', 'n_estimators': 209, 'learning_rate': 0.0017639419237983974, 'max_depth': 4, 'subsample': 0.9913331459164753}. Best is trial 3 with value: 0.8430493273542601.\n",
      "[I 2024-12-18 15:22:49,082] Trial 21 finished with value: 0.8340807174887892 and parameters: {'model': 'RandomForest', 'n_estimators': 181, 'max_depth': 19, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8430493273542601.\n",
      "[I 2024-12-18 15:22:49,271] Trial 22 finished with value: 0.8295964125560538 and parameters: {'model': 'RandomForest', 'n_estimators': 183, 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8430493273542601.\n",
      "[I 2024-12-18 15:22:49,418] Trial 23 finished with value: 0.8161434977578476 and parameters: {'model': 'RandomForest', 'n_estimators': 148, 'max_depth': 17, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8430493273542601.\n",
      "[I 2024-12-18 15:22:49,622] Trial 24 finished with value: 0.8071748878923767 and parameters: {'model': 'RandomForest', 'n_estimators': 224, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.8430493273542601.\n",
      "[I 2024-12-18 15:22:49,733] Trial 25 finished with value: 0.8071748878923767 and parameters: {'model': 'RandomForest', 'n_estimators': 102, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.8430493273542601.\n",
      "[I 2024-12-18 15:22:49,991] Trial 26 finished with value: 0.8251121076233184 and parameters: {'model': 'RandomForest', 'n_estimators': 276, 'max_depth': 16, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8430493273542601.\n",
      "[I 2024-12-18 15:22:50,177] Trial 27 finished with value: 0.8251121076233184 and parameters: {'model': 'RandomForest', 'n_estimators': 187, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8430493273542601.\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6996\\1016786673.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e5),\n",
      "[I 2024-12-18 15:22:50,191] Trial 28 finished with value: 0.600896860986547 and parameters: {'model': 'LogisticRegression', 'C': 2.1209245733678173e-05, 'solver': 'lbfgs'}. Best is trial 3 with value: 0.8430493273542601.\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6996\\1016786673.py:79: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6996\\1016786673.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0)\n",
      "[I 2024-12-18 15:22:50,503] Trial 29 finished with value: 0.7847533632286996 and parameters: {'model': 'GradientBoosting', 'n_estimators': 154, 'learning_rate': 0.09946769815760588, 'max_depth': 6, 'subsample': 0.7592070659420991}. Best is trial 3 with value: 0.8430493273542601.\n",
      "[I 2024-12-18 15:22:50,696] Trial 30 finished with value: 0.8251121076233184 and parameters: {'model': 'RandomForest', 'n_estimators': 202, 'max_depth': 19, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.8430493273542601.\n",
      "[I 2024-12-18 15:22:50,887] Trial 31 finished with value: 0.8295964125560538 and parameters: {'model': 'RandomForest', 'n_estimators': 187, 'max_depth': 18, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8430493273542601.\n",
      "[I 2024-12-18 15:22:51,070] Trial 32 finished with value: 0.8340807174887892 and parameters: {'model': 'RandomForest', 'n_estimators': 178, 'max_depth': 19, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8430493273542601.\n",
      "[I 2024-12-18 15:22:51,251] Trial 33 finished with value: 0.8161434977578476 and parameters: {'model': 'RandomForest', 'n_estimators': 175, 'max_depth': 14, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.8430493273542601.\n",
      "[I 2024-12-18 15:22:51,384] Trial 34 finished with value: 0.8251121076233184 and parameters: {'model': 'RandomForest', 'n_estimators': 129, 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8430493273542601.\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6996\\1016786673.py:79: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6996\\1016786673.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0)\n",
      "[I 2024-12-18 15:22:51,819] Trial 35 finished with value: 0.8251121076233184 and parameters: {'model': 'GradientBoosting', 'n_estimators': 219, 'learning_rate': 0.004197589547396862, 'max_depth': 6, 'subsample': 0.7083854290350722}. Best is trial 3 with value: 0.8430493273542601.\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6996\\1016786673.py:79: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6996\\1016786673.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0)\n",
      "[I 2024-12-18 15:22:52,192] Trial 36 finished with value: 0.8026905829596412 and parameters: {'model': 'GradientBoosting', 'n_estimators': 244, 'learning_rate': 0.030462578229245925, 'max_depth': 5, 'subsample': 0.9109206169682992}. Best is trial 3 with value: 0.8430493273542601.\n",
      "[I 2024-12-18 15:22:52,363] Trial 37 finished with value: 0.8385650224215246 and parameters: {'model': 'RandomForest', 'n_estimators': 171, 'max_depth': 19, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8430493273542601.\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6996\\1016786673.py:79: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6996\\1016786673.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0)\n",
      "[I 2024-12-18 15:22:52,553] Trial 38 finished with value: 0.7847533632286996 and parameters: {'model': 'GradientBoosting', 'n_estimators': 161, 'learning_rate': 0.004212814696966103, 'max_depth': 4, 'subsample': 0.7837565043746153}. Best is trial 3 with value: 0.8430493273542601.\n",
      "[I 2024-12-18 15:22:52,698] Trial 39 finished with value: 0.820627802690583 and parameters: {'model': 'RandomForest', 'n_estimators': 143, 'max_depth': 16, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.8430493273542601.\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6996\\1016786673.py:79: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6996\\1016786673.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0)\n",
      "[I 2024-12-18 15:22:52,972] Trial 40 finished with value: 0.8161434977578476 and parameters: {'model': 'GradientBoosting', 'n_estimators': 132, 'learning_rate': 0.039318917332000845, 'max_depth': 6, 'subsample': 0.882523718229486}. Best is trial 3 with value: 0.8430493273542601.\n",
      "[I 2024-12-18 15:22:53,144] Trial 41 finished with value: 0.8385650224215246 and parameters: {'model': 'RandomForest', 'n_estimators': 174, 'max_depth': 19, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8430493273542601.\n",
      "[I 2024-12-18 15:22:53,327] Trial 42 finished with value: 0.8295964125560538 and parameters: {'model': 'RandomForest', 'n_estimators': 164, 'max_depth': 19, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8430493273542601.\n",
      "[I 2024-12-18 15:22:53,569] Trial 43 finished with value: 0.8251121076233184 and parameters: {'model': 'RandomForest', 'n_estimators': 195, 'max_depth': 17, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8430493273542601.\n",
      "[I 2024-12-18 15:22:53,765] Trial 44 finished with value: 0.7982062780269058 and parameters: {'model': 'RandomForest', 'n_estimators': 172, 'max_depth': 19, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.8430493273542601.\n",
      "[I 2024-12-18 15:22:53,962] Trial 45 finished with value: 0.8161434977578476 and parameters: {'model': 'RandomForest', 'n_estimators': 204, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8430493273542601.\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6996\\1016786673.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e5),\n",
      "[I 2024-12-18 15:22:53,970] Trial 46 finished with value: 0.8071748878923767 and parameters: {'model': 'LogisticRegression', 'C': 0.2870856466534863, 'solver': 'liblinear'}. Best is trial 3 with value: 0.8430493273542601.\n",
      "[I 2024-12-18 15:22:54,130] Trial 47 finished with value: 0.8251121076233184 and parameters: {'model': 'RandomForest', 'n_estimators': 155, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8430493273542601.\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6996\\1016786673.py:79: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6996\\1016786673.py:81: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.7, 1.0)\n",
      "[I 2024-12-18 15:22:54,397] Trial 48 finished with value: 0.7802690582959642 and parameters: {'model': 'GradientBoosting', 'n_estimators': 285, 'learning_rate': 0.0010248259324845905, 'max_depth': 3, 'subsample': 0.9945403197883241}. Best is trial 3 with value: 0.8430493273542601.\n",
      "[I 2024-12-18 15:22:54,610] Trial 49 finished with value: 0.820627802690583 and parameters: {'model': 'RandomForest', 'n_estimators': 215, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.8430493273542601.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'model': 'GradientBoosting', 'n_estimators': 161, 'learning_rate': 0.013583715227801349, 'max_depth': 6, 'subsample': 0.7945475301527058}\n",
      "Validation Accuracy: 0.8430493273542601\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88       134\n",
      "           1       0.86      0.73      0.79        89\n",
      "\n",
      "    accuracy                           0.84       223\n",
      "   macro avg       0.85      0.82      0.83       223\n",
      "weighted avg       0.84      0.84      0.84       223\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../model/best_titanic_model.pkl']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import optuna\n",
    "import joblib\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "test_df = pd.read_csv(\"../data/test.csv\")\n",
    "\n",
    "# Handle missing values\n",
    "for dataset in [train_df, test_df]:\n",
    "    dataset['Age'] = dataset.groupby(['Pclass', 'Sex'])['Age'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "train_df['Embarked'] = train_df['Embarked'].fillna(train_df['Embarked'].mode()[0])\n",
    "test_df['Fare'] = test_df['Fare'].fillna(test_df['Fare'].median())\n",
    "\n",
    "train_df.drop(columns=['Cabin'], inplace=True)\n",
    "test_df.drop(columns=['Cabin'], inplace=True)\n",
    "\n",
    "# Encode categorical features\n",
    "le = LabelEncoder()\n",
    "for dataset in [train_df, test_df]:\n",
    "    dataset['Sex'] = le.fit_transform(dataset['Sex'])\n",
    "    dataset['Embarked'] = le.fit_transform(dataset['Embarked'])\n",
    "\n",
    "# Feature Engineering\n",
    "for dataset in [train_df, test_df]:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "    dataset['IsAlone'] = np.where(dataset['FamilySize'] > 1, 0, 1)\n",
    "    dataset['AgeBin'] = pd.cut(dataset['Age'], bins=[0, 12, 18, 50, 80], labels=[0, 1, 2, 3])\n",
    "    dataset['FareBin'] = pd.qcut(dataset['Fare'], 4, labels=[0, 1, 2, 3])\n",
    "\n",
    "train_df.drop(columns=['Name', 'Ticket', 'PassengerId'], inplace=True)\n",
    "test_ids = test_df['PassengerId']\n",
    "test_df.drop(columns=['Name', 'Ticket', 'PassengerId'], inplace=True)\n",
    "\n",
    "# Split the data into features and target\n",
    "X = train_df.drop(columns=['Survived'])\n",
    "y = train_df['Survived']\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "X[['Age', 'Fare']] = scaler.fit_transform(X[['Age', 'Fare']])\n",
    "test_df[['Age', 'Fare']] = scaler.transform(test_df[['Age', 'Fare']])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Choose a model\n",
    "    model_name = trial.suggest_categorical('model', ['LogisticRegression', 'RandomForest', 'GradientBoosting'])\n",
    "\n",
    "    # Hyperparameters for each model\n",
    "    if model_name == 'LogisticRegression':\n",
    "        model = LogisticRegression(max_iter=1000)\n",
    "        param = {\n",
    "            'C': trial.suggest_loguniform('C', 1e-5, 1e5),\n",
    "            'solver': trial.suggest_categorical('solver', ['lbfgs', 'liblinear'])\n",
    "        }\n",
    "    elif model_name == 'RandomForest':\n",
    "        model = RandomForestClassifier(random_state=42)\n",
    "        param = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n",
    "            'max_depth': trial.suggest_int('max_depth', 5, 20),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 4)\n",
    "        }\n",
    "    elif model_name == 'GradientBoosting':\n",
    "        model = GradientBoostingClassifier(random_state=42)\n",
    "        param = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n",
    "            'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 7),\n",
    "            'subsample': trial.suggest_uniform('subsample', 0.7, 1.0)\n",
    "        }\n",
    "    \n",
    "    # Set parameters and train model\n",
    "    model.set_params(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_valid, model.predict(X_valid))\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# Create a study and optimize\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters: \", study.best_params)\n",
    "\n",
    "# Train the best model\n",
    "best_model_name = study.best_params['model']\n",
    "best_model = None\n",
    "\n",
    "# Create the model based on the best model name\n",
    "if best_model_name == 'LogisticRegression':\n",
    "    best_model = LogisticRegression(max_iter=1000)\n",
    "    best_model.set_params(\n",
    "        C=study.best_params['C'], \n",
    "        solver=study.best_params['solver']\n",
    "    )\n",
    "elif best_model_name == 'RandomForest':\n",
    "    best_model = RandomForestClassifier(random_state=42)\n",
    "    best_model.set_params(\n",
    "        n_estimators=study.best_params['n_estimators'],\n",
    "        max_depth=study.best_params['max_depth'],\n",
    "        min_samples_split=study.best_params['min_samples_split'],\n",
    "        min_samples_leaf=study.best_params['min_samples_leaf']\n",
    "    )\n",
    "elif best_model_name == 'GradientBoosting':\n",
    "    best_model = GradientBoostingClassifier(random_state=42)\n",
    "    best_model.set_params(\n",
    "        n_estimators=study.best_params['n_estimators'],\n",
    "        learning_rate=study.best_params['learning_rate'],\n",
    "        max_depth=study.best_params['max_depth'],\n",
    "        subsample=study.best_params['subsample']\n",
    "    )\n",
    "\n",
    "# Train the best model\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on validation set\n",
    "y_valid_pred = best_model.predict(X_valid)\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_valid, y_valid_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_valid, y_valid_pred))\n",
    "\n",
    "# Predict on test set\n",
    "y_test_pred = best_model.predict(test_df)\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "submission = pd.DataFrame({\"PassengerId\": test_ids, \"Survived\": y_test_pred})\n",
    "submission.to_csv(\"../results/titanic_submission.csv\", index=False)\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(best_model, '../model/best_titanic_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
