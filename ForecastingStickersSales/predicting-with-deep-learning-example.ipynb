{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":85723,"databundleVersionId":10652996,"sourceType":"competition"},{"sourceId":10379119,"sourceType":"datasetVersion","datasetId":6429415},{"sourceId":10380918,"sourceType":"datasetVersion","datasetId":6430662}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Predicting Sales Using Deep Learning: A Step-by-Step Guide\n","metadata":{}},{"cell_type":"markdown","source":"## 1. Loading the Data\n\nWe start by importing the necessary libraries and loading the training and testing data from CSV files.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, Embedding, Flatten, concatenate, BatchNormalization, Dropout, Add, Lambda\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split\nimport holidays\n\n# Load datasets\ntrain = pd.read_csv('/kaggle/input/train-pssse1/train_PSSSE1.csv')\ntest = pd.read_csv('/kaggle/input/playground-series-s5e1/test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T12:20:44.940552Z","iopub.execute_input":"2025-01-26T12:20:44.940909Z","iopub.status.idle":"2025-01-26T12:20:45.163769Z","shell.execute_reply.started":"2025-01-26T12:20:44.940862Z","shell.execute_reply":"2025-01-26T12:20:45.162862Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"# Set seed for reproducibility\nSEED = 42\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T12:20:45.165007Z","iopub.execute_input":"2025-01-26T12:20:45.165324Z","iopub.status.idle":"2025-01-26T12:20:45.228897Z","shell.execute_reply.started":"2025-01-26T12:20:45.165292Z","shell.execute_reply":"2025-01-26T12:20:45.227698Z"}},"outputs":[],"execution_count":42},{"cell_type":"markdown","source":"## 2. Data Preprocessing and Feature Engineering","metadata":{}},{"cell_type":"code","source":"# Handle missing values\ntrain = train.dropna()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T12:20:45.232039Z","iopub.execute_input":"2025-01-26T12:20:45.232298Z","iopub.status.idle":"2025-01-26T12:20:45.289282Z","shell.execute_reply.started":"2025-01-26T12:20:45.232272Z","shell.execute_reply":"2025-01-26T12:20:45.288453Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"# Handle 'id' Column\nids = test['id']\ntrain.drop(columns=['id'], inplace=True) \ntest.drop(columns=['id'], inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T12:20:45.290758Z","iopub.execute_input":"2025-01-26T12:20:45.291078Z","iopub.status.idle":"2025-01-26T12:20:45.305188Z","shell.execute_reply.started":"2025-01-26T12:20:45.291043Z","shell.execute_reply":"2025-01-26T12:20:45.304401Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"# Adding Advanced Features: Public Holidays\ndef add_holidays(df):\n    countries_holidays = {\n        'Finland': holidays.Finland(),\n        'Canada': holidays.Canada(),\n        'Italy': holidays.Italy(),\n        'Kenya': holidays.Kenya(),\n        'Singapore': holidays.Singapore(),\n        'Norway': holidays.Norway()\n    }\n    \n    df['is_holiday'] = df.apply(\n        lambda row: int(row['date'] in countries_holidays[row['country']]), axis=1\n    )\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T12:20:45.305971Z","iopub.execute_input":"2025-01-26T12:20:45.306185Z","iopub.status.idle":"2025-01-26T12:20:45.311244Z","shell.execute_reply.started":"2025-01-26T12:20:45.306163Z","shell.execute_reply":"2025-01-26T12:20:45.310410Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"# Transforming Date Features\ndef transform_date(df):\n    df['date'] = pd.to_datetime(df['date'])\n    df['year'] = df['date'].dt.year\n    df['month'] = df['date'].dt.month\n    df['day'] = df['date'].dt.day\n    df['weekday'] = df['date'].dt.weekday\n    df['day_of_year'] = df['date'].dt.dayofyear\n    df['week_of_year'] = df['date'].dt.isocalendar().week\n    df['is_weekend'] = (df['weekday'] >= 5).astype(int)\n    df['season'] = ((df['month'] % 12 + 3) // 3)  \n    df['elapsed_days'] = (df['date'] - df['date'].min()).dt.days\n    df['is_end_of_month'] = df['date'].dt.is_month_end.astype(int)\n    df['is_end_of_quarter'] = df['date'].dt.is_quarter_end.astype(int)\n    \n    # Sinusoidal transformations for cyclic features\n    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n    df['day_sin'] = np.sin(2 * np.pi * df['day_of_year'] / 365)\n    df['day_cos'] = np.cos(2 * np.pi * df['day_of_year'] / 365)\n    \n    return add_holidays(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T12:20:45.312146Z","iopub.execute_input":"2025-01-26T12:20:45.312461Z","iopub.status.idle":"2025-01-26T12:20:45.326924Z","shell.execute_reply.started":"2025-01-26T12:20:45.312430Z","shell.execute_reply":"2025-01-26T12:20:45.326215Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"# Transform train and test data\ntrain = transform_date(train)\ntest = transform_date(test)\n\n# Log-transform the target variable\ntrain['num_sold'] = np.log1p(train['num_sold'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T12:20:45.327595Z","iopub.execute_input":"2025-01-26T12:20:45.327788Z","iopub.status.idle":"2025-01-26T12:20:49.148856Z","shell.execute_reply.started":"2025-01-26T12:20:45.327770Z","shell.execute_reply":"2025-01-26T12:20:49.148143Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"# Split train data into features and target\nX = train.drop(columns=['num_sold', 'date'])\ny = train['num_sold']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T12:20:49.149720Z","iopub.execute_input":"2025-01-26T12:20:49.149964Z","iopub.status.idle":"2025-01-26T12:20:49.167204Z","shell.execute_reply.started":"2025-01-26T12:20:49.149939Z","shell.execute_reply":"2025-01-26T12:20:49.166643Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"# Encoding Categorical Features:\ncategorical_cols = ['country', 'store', 'product', 'is_weekend', 'season', 'is_end_of_month', 'is_end_of_quarter', 'is_holiday']\nnumerical_cols = [col for col in X.columns if col not in categorical_cols]\n\nencoders = {}\nfor col in categorical_cols:\n    le = LabelEncoder()\n    X[col] = le.fit_transform(X[col])\n    test[col] = le.transform(test[col])\n    encoders[col] = le","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T12:20:49.169193Z","iopub.execute_input":"2025-01-26T12:20:49.169415Z","iopub.status.idle":"2025-01-26T12:20:49.417760Z","shell.execute_reply.started":"2025-01-26T12:20:49.169388Z","shell.execute_reply":"2025-01-26T12:20:49.417025Z"}},"outputs":[],"execution_count":49},{"cell_type":"markdown","source":"### Explanation:\n- **Label Encoding**: Converts categorical features into integer labels using **LabelEncoder**.","metadata":{}},{"cell_type":"code","source":"# Scaling Numerical Features:\nscaler = MinMaxScaler()\nX[numerical_cols] = scaler.fit_transform(X[numerical_cols])\ntest[numerical_cols] = scaler.transform(test[numerical_cols])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T12:20:49.418922Z","iopub.execute_input":"2025-01-26T12:20:49.419180Z","iopub.status.idle":"2025-01-26T12:20:49.591292Z","shell.execute_reply.started":"2025-01-26T12:20:49.419158Z","shell.execute_reply":"2025-01-26T12:20:49.590585Z"}},"outputs":[],"execution_count":50},{"cell_type":"markdown","source":"### Explanation:\n- **MinMax Scaling**: We scale the numerical features to the range [0, 1] for better model performance.","metadata":{}},{"cell_type":"markdown","source":"## 3. Building the Model: Neural Network Architecture","metadata":{}},{"cell_type":"markdown","source":"Now, we define a neural network architecture. This includes input layers for both categorical and numerical features, embedding layers for categorical variables, and multiple dense layers.","metadata":{}},{"cell_type":"code","source":"def attention_block(x):\n    attention = Dense(x.shape[-1], activation='softmax')(x)\n    return Lambda(lambda inputs: inputs[0] * inputs[1])([x, attention])\n\ndef build_advanced_model():\n    # Inputs for categorical features\n    inputs = []\n    embeddings = []\n    for col in categorical_cols:\n        unique_values = X[col].nunique()\n        input_cat = Input(shape=(1,))\n        embedding = Embedding(input_dim=unique_values, output_dim=min(50, (unique_values + 1) // 2))(input_cat)\n        flatten = Flatten()(embedding)\n        inputs.append(input_cat)\n        embeddings.append(flatten)\n\n    # Input for numerical features\n    input_num = Input(shape=(len(numerical_cols),))\n    inputs.append(input_num)\n    \n    # Combine all inputs\n    x = concatenate(embeddings + [input_num])\n\n    # Add dense layers with residual connections\n    x = Dense(512, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    residual = x\n\n    x = Dense(256, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.4)(x)\n\n    residual = Dense(256)(residual)\n    x = Add()([x, residual])\n\n    x = attention_block(x)  # Attention mechanism\n\n    x = Dense(128, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.3)(x)\n\n    x = Dense(1)(x)  # Linear activation for regression output\n    \n    model = Model(inputs=inputs, outputs=x)\n    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T12:20:49.592123Z","iopub.execute_input":"2025-01-26T12:20:49.592444Z","iopub.status.idle":"2025-01-26T12:20:49.599579Z","shell.execute_reply.started":"2025-01-26T12:20:49.592407Z","shell.execute_reply":"2025-01-26T12:20:49.598697Z"}},"outputs":[],"execution_count":51},{"cell_type":"markdown","source":"### Explanation:\n- **Embedding Layer**: This is used for categorical variables to learn dense representations.\n- **Attention Mechanism**: Adds attention to the model to focus on important features.\n- **Residual Connections**: Help the model to learn better by passing the previous layer's output to later layers.\n- **Dropout**: Prevents overfitting by randomly turning off some neurons during training.","metadata":{}},{"cell_type":"markdown","source":"## 4. Training the Model\n","metadata":{}},{"cell_type":"markdown","source":"Now we split the data into training and validation sets and train the model with early stopping and learning rate reduction callbacks.","metadata":{}},{"cell_type":"code","source":"# Prepare inputs for the model\ndef prepare_inputs(X):\n    inputs = [X[col] for col in categorical_cols]\n    inputs.append(X[numerical_cols].values)\n    return inputs\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1, random_state=42)\n\nmodel = build_advanced_model()\n\nhistory = model.fit(\n    prepare_inputs(X_train),\n    y_train,\n    validation_data=(prepare_inputs(X_valid), y_valid),\n    epochs=200,\n    batch_size=1024,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True, min_delta=0.001),\n        tf.keras.callbacks.ReduceLROnPlateau(patience=3, factor=0.5, min_lr=1e-6)\n    ]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T12:20:49.600290Z","iopub.execute_input":"2025-01-26T12:20:49.600508Z","iopub.status.idle":"2025-01-26T12:21:19.766915Z","shell.execute_reply.started":"2025-01-26T12:20:49.600488Z","shell.execute_reply":"2025-01-26T12:21:19.766271Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/200\n\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - loss: 25.4878 - mae: 4.6086 - val_loss: 2.5155 - val_mae: 1.2536 - learning_rate: 0.0010\nEpoch 2/200\n\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4456 - mae: 0.5108 - val_loss: 2.0757 - val_mae: 1.1031 - learning_rate: 0.0010\nEpoch 3/200\n\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2988 - mae: 0.4274 - val_loss: 0.6937 - val_mae: 0.6425 - learning_rate: 0.0010\nEpoch 4/200\n\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2551 - mae: 0.3967 - val_loss: 0.0611 - val_mae: 0.1839 - learning_rate: 0.0010\nEpoch 5/200\n\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2345 - mae: 0.3809 - val_loss: 0.0202 - val_mae: 0.1135 - learning_rate: 0.0010\nEpoch 6/200\n\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2124 - mae: 0.3646 - val_loss: 0.0148 - val_mae: 0.0962 - learning_rate: 0.0010\nEpoch 7/200\n\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2052 - mae: 0.3569 - val_loss: 0.0132 - val_mae: 0.0906 - learning_rate: 0.0010\nEpoch 8/200\n\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1968 - mae: 0.3503 - val_loss: 0.0228 - val_mae: 0.1240 - learning_rate: 0.0010\nEpoch 9/200\n\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1908 - mae: 0.3449 - val_loss: 0.0125 - val_mae: 0.0888 - learning_rate: 0.0010\nEpoch 10/200\n\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1881 - mae: 0.3427 - val_loss: 0.0157 - val_mae: 0.1005 - learning_rate: 0.0010\nEpoch 11/200\n\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1825 - mae: 0.3380 - val_loss: 0.0110 - val_mae: 0.0825 - learning_rate: 0.0010\nEpoch 12/200\n\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1816 - mae: 0.3356 - val_loss: 0.0119 - val_mae: 0.0834 - learning_rate: 0.0010\nEpoch 13/200\n\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1774 - mae: 0.3331 - val_loss: 0.0109 - val_mae: 0.0820 - learning_rate: 0.0010\nEpoch 14/200\n\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1745 - mae: 0.3303 - val_loss: 0.0091 - val_mae: 0.0744 - learning_rate: 0.0010\nEpoch 15/200\n\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1733 - mae: 0.3293 - val_loss: 0.0094 - val_mae: 0.0761 - learning_rate: 0.0010\nEpoch 16/200\n\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1714 - mae: 0.3270 - val_loss: 0.0139 - val_mae: 0.0896 - learning_rate: 0.0010\nEpoch 17/200\n\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1692 - mae: 0.3248 - val_loss: 0.0106 - val_mae: 0.0808 - learning_rate: 0.0010\nEpoch 18/200\n\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1661 - mae: 0.3222 - val_loss: 0.0090 - val_mae: 0.0749 - learning_rate: 5.0000e-04\nEpoch 19/200\n\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1646 - mae: 0.3207 - val_loss: 0.0119 - val_mae: 0.0861 - learning_rate: 5.0000e-04\nEpoch 20/200\n\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1632 - mae: 0.3198 - val_loss: 0.0081 - val_mae: 0.0708 - learning_rate: 5.0000e-04\nEpoch 21/200\n\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1643 - mae: 0.3210 - val_loss: 0.0087 - val_mae: 0.0730 - learning_rate: 5.0000e-04\nEpoch 22/200\n\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1628 - mae: 0.3192 - val_loss: 0.0110 - val_mae: 0.0822 - learning_rate: 5.0000e-04\nEpoch 23/200\n\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1619 - mae: 0.3185 - val_loss: 0.0098 - val_mae: 0.0773 - learning_rate: 5.0000e-04\nEpoch 24/200\n\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1597 - mae: 0.3159 - val_loss: 0.0083 - val_mae: 0.0710 - learning_rate: 2.5000e-04\n","output_type":"stream"}],"execution_count":52},{"cell_type":"markdown","source":"### Explanation:\n- **EarlyStopping**: Stops training if the model's performance stops improving.\n- **ReduceLROnPlateau**: Reduces the learning rate when the model plateaus.","metadata":{}},{"cell_type":"markdown","source":"## 5. Making Predictions","metadata":{}},{"cell_type":"markdown","source":"After training, we make predictions on the test set and reverse the log transformation.","metadata":{}},{"cell_type":"code","source":"test_predictions = np.expm1(model.predict(prepare_inputs(test)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T12:21:19.768311Z","iopub.execute_input":"2025-01-26T12:21:19.768590Z","iopub.status.idle":"2025-01-26T12:21:28.373125Z","shell.execute_reply.started":"2025-01-26T12:21:19.768567Z","shell.execute_reply":"2025-01-26T12:21:28.372417Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m3080/3080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step\n","output_type":"stream"}],"execution_count":53},{"cell_type":"markdown","source":"## 6. Submission","metadata":{}},{"cell_type":"code","source":"submission = pd.DataFrame({\n    'id': ids,\n    'num_sold': test_predictions.flatten()\n})\n\nsubmission.to_csv('submission.csv', index=False)\nprint(\"submission.csv saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T12:21:28.373869Z","iopub.execute_input":"2025-01-26T12:21:28.374096Z","iopub.status.idle":"2025-01-26T12:21:28.493710Z","shell.execute_reply.started":"2025-01-26T12:21:28.374076Z","shell.execute_reply":"2025-01-26T12:21:28.492954Z"}},"outputs":[{"name":"stdout","text":"submission.csv saved.\n","output_type":"stream"}],"execution_count":54}]}